# ç¬¬ä¸€æ¬¡å®éªŒ
åœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬åŸºäºæ•°æ®é›†çš„ç‰¹å¾å’Œç»éªŒè®¾è®¡äº†ä¸€äº›è¶…å‚æ•°ï¼Œå±•å¼€ç¬¬ä¸€æ¬¡åˆå§‹çš„è®­ç»ƒå¾—åˆ°äº†å¯ä¾›æˆ‘ä»¬è¿›è¡Œæ€§èƒ½å¯¹æ¯”çš„åŸºå‡†ç»“æœã€‚æˆ‘ä»¬è®­ç»ƒçš„è®¾ç½®å¦‚ä¸‹ï¼š
```python
import warnings
warnings.filterwarnings('ignore')
from ultralytics import YOLO
# åŠ è½½æ¨¡å‹
model = YOLO('yolov8m.pt')
# å¼€å§‹è®­ç»ƒä»»åŠ¡
model.train(data="/data/coding/rec/data.yaml",
            epochs=200, 
            batch=16, 
            imgsz=640, 
            lr0=0.005, 
            device=0,
            weight_decay=0.0005,
            name='yolov8s_eucalyptus_advanced',
            # å¯ä»¥ä½¿ç”¨focal losså¤„ç†ç±»åˆ«ä¸å¹³è¡¡
            augment=True,  # å¯ç”¨æ•°æ®å¢å¼º
            #fl_loss=1.5,  # focal loss gammaå‚æ•°
            # å¢åŠ åˆ†ç±»æŸå¤±çš„æƒé‡ï¼Œå¸®åŠ©æ›´å¥½åŒºåˆ†èƒŒæ™¯
            cls=1,
            box=0.08,
            iou=0.45,
            conf=0.5,
            hsv_h=0.1,  # è‰²è°ƒå¢å¼º
            hsv_s=0.7,  # é¥±å’Œåº¦å¢å¼º
            hsv_v=0.4,  # æ˜åº¦å¢å¼º
            degrees=15.0,  # æ—‹è½¬è§’åº¦èŒƒå›´
            translate=0.1,  # å¹³ç§»èŒƒå›´
            scale=0.5,  # ç¼©æ”¾èŒƒå›´
            shear=2.0,  # å‰ªåˆ‡èŒƒå›´
            flipud=0.5,  # ä¸Šä¸‹ç¿»è½¬æ¦‚ç‡
            fliplr=0.5,  # å·¦å³ç¿»è½¬æ¦‚ç‡
            mosaic=1.0,  # mosaicæ•°æ®å¢å¼ºæ¦‚ç‡
            mixup=0.1,  # mixupæ•°æ®å¢å¼ºæ¦‚ç‡
            copy_paste=0.5  # éšæœºç²˜è´´èƒŒæ™¯
            )

```
å¹¶ä¸”å¾—åˆ°äº†å¦‚ä¸‹çš„ç»“æœï¼š
![results](assets/results.png)
æˆ‘ä»¬å¯ä»¥çœ‹å‡ºæ¥è®­ç»ƒé›†å’ŒéªŒè¯é›†ä¸Šè¿™ä¸ªæ¨¡å‹æŸå¤±å‡½æ•°çš„æ”¶æ•›éƒ½æ˜¯ä¸é”™çš„ï¼Œè€Œä¸”ç²¾åº¦å’Œå¬å›ç‡éƒ½æ¥è¿‘1ï¼ŒéªŒè¯é›†ä¸Šçš„mAP50æ¥è¿‘1ï¼ŒmAP50-95æ¥è¿‘0.9ï¼Œæ˜¯ä¸ªæ•ˆæœå¾ˆå¥½çš„æ¨¡å‹ã€‚è¯´åˆ°mAPï¼Œå°±ä¸å¾—ä¸æåˆ°ä¸€äº›é‡è¦çš„æ€§èƒ½æŒ‡æ ‡ã€‚

|          | true | false |
|:--------:|:----:|:-----:|
| positive | TP   | FN    |
| negative | FP   | TN    |

YOLOä¸­æœ‰å¦‚ä¸‹çš„é˜ˆå€¼ï¼š

ç½®ä¿¡åº¦é˜ˆå€¼ï¼šå¯¹æ¯ä¸ªé¢„æµ‹æ¡†çš„ç½®ä¿¡åº¦åˆ†æ•°çš„æ ‡å‡†ã€‚æ¨¡å‹ä¼šä¸ºæ¯ä¸ªé¢„æµ‹æ¡†æä¾›ä¸€ä¸ªç½®ä¿¡åº¦å€¼ï¼ˆä¾‹å¦‚ç›®æ ‡çš„å­˜åœ¨æ¦‚ç‡ï¼‰ï¼Œè¡¨ç¤ºæ¨¡å‹è®¤ä¸ºè¯¥æ¡†åŒ…å«ç›®æ ‡çš„ä¿¡å¿ƒæœ‰å¤šå¤§ã€‚ä¸€èˆ¬éƒ½æ˜¯pr(object)ä¸IoUçš„ä¹˜ç§¯ï¼ŒPr(Object) æ˜¯è¾¹ç•Œæ¡†å†…å­˜åœ¨å¯¹è±¡çš„æ¦‚ç‡ã€‚å¦‚æœè¾¹ç•Œæ¡†å†…æœ‰å¯¹è±¡ï¼Œåˆ™Pr(Object)=1ï¼›åä¹‹ï¼Œåˆ™Pr(Object)=0ã€‚

IoUé˜ˆå€¼ï¼šIoUè¡¡é‡çš„æ˜¯ä¸¤ä¸ªåŒºåŸŸé‡å çš„ç¨‹åº¦ã€‚é¢„æµ‹æ¡†ä¸çœŸå®æ¡†çš„IoUå¤§äºç­‰äºæŸä¸ªé˜ˆå€¼æ—¶ï¼Œæ‰è®¤ä¸ºè¿™ä¸ªé¢„æµ‹æ˜¯æœ‰æ•ˆçš„ï¼Œå·¥ä¸šé¢†åŸŸä¸€èˆ¬ä¸º0.5ã€‚IOUæ–¹æ³•æ¯”è¾ƒç®€å•ç›´è§‚ï¼Œè®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„äº¤é›†ä¸å¹¶é›†ä¹‹é—´çš„æ¯”å€¼ã€‚å½“IoUæ¥è¿‘1æ—¶ï¼Œæ„å‘³ç€ä¸¤ä¸ªè¾¹ç•Œæ¡†é«˜åº¦é‡å ï¼Œå³é¢„æµ‹çš„ä½ç½®ä¸çœŸå®ä½ç½®é«˜åº¦ä¸€è‡´ï¼›å½“IoUæ¥è¿‘0æ—¶ï¼Œè¡¨ç¤ºä¸¤ä¸ªè¾¹ç•Œæ¡†å‡ ä¹æ²¡æœ‰é‡å ï¼Œå³é¢„æµ‹åç¦»çœŸå®ä½ç½®å¾ˆå¤§ã€‚ IoUçš„è®¡ç®—æ–¹å¼å¦‚ä¸‹ï¼šç¡®å®šä¸¤ä¸ªè¾¹ç•Œæ¡†çš„åæ ‡è¡¨ç¤ºå½¢å¼ã€‚è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„äº¤é›†é¢ç§¯ï¼šå°†ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„åŒºåŸŸè¿›è¡Œé‡å ï¼Œè®¡ç®—é‡å éƒ¨åˆ†çš„é¢ç§¯ã€‚è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„å¹¶é›†é¢ç§¯ï¼šå°†ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„åŒºåŸŸè¿›è¡Œåˆå¹¶ï¼Œè®¡ç®—åˆå¹¶åçš„é¢ç§¯ã€‚è®¡ç®—IoUï¼šå°†äº¤é›†é¢ç§¯é™¤ä»¥å¹¶é›†é¢ç§¯ï¼Œå¾—åˆ°IoUçš„å€¼ã€‚
è¿™é‡Œä¸¤ä¸ªé˜ˆå€¼ï¼Œåœ¨æˆ‘çœ‹æ¥IoUé˜ˆå€¼å†³å®šå®šä½ä¸¥æ ¼æ€§ï¼Œè€Œç½®ä¿¡åº¦æ˜¯ç”±IoUé˜ˆå€¼è®¡ç®—å¾—åˆ°çš„ï¼Œå†³å®šäº†ç²¾ç¡®åº¦ä¸å¬å›ç‡çš„å¹³è¡¡ã€‚

YOLOä¸­æœ‰å¦‚ä¸‹ç›¸å¯¹å•ä¸€çš„è¯„ä»·æŒ‡æ ‡ï¼ˆå³çœŸæ­£ä¾‹ã€å‡åä¾‹ã€å‡æ­£ä¾‹ã€çœŸåä¾‹ï¼‰ï¼š

Pï¼šç²¾ç¡®ç‡ï¼Œå¯¹ç±»Aæ¥è¯´ï¼šP = TP / TP+FP

Rï¼šå¬å›ç‡ï¼Œå¯¹ç±»Aæ¥è¯´ï¼šR = TP / TP+FN

è¿™é‡Œæ’å…¥ä¸¾ä¸ªä¾‹å­ä»¥ä¾¿ç†è§£ï¼šæŸä¸ªæ¨¡å‹è¦å¯¹åŠ¨ç‰©è¿›è¡Œåˆ†ç±»ï¼Œåˆ†ä¸ºçŒ«ä¸éçŒ«ä¸¤ç±»ã€‚æ ·æœ¬ä¸­çŒ«æœ‰350ä»½ï¼ŒéçŒ«æœ‰150ä»½ã€‚é¢„æµ‹å‡ºäº†400ä»½è¢«è®¤ä¸ºæ˜¯çŒ«ï¼Œå…¶ä¸­ï¼Œæ­£ç¡®çš„æœ‰300ä»½ï¼Œé”™è¯¯çš„æœ‰100ä»½ã€‚åˆ™P = 300 / 400 = 0.75ï¼ŒR = 300 / 350 â‰ˆ 0.86ã€‚æ¥ä¸Šæ–‡ï¼Œæé«˜ç½®ä¿¡åº¦é˜ˆå€¼ä¼šå¯¼è‡´FPå‡å°‘ï¼ŒTPå¯èƒ½å‡å°‘ï¼Œä»è€Œç²¾ç¡®åº¦ä¸Šå‡ï¼Œå¬å›ç‡ä¸‹é™ã€‚é™ä½ç½®ä¿¡åº¦é˜ˆå€¼å¯¼è‡´TPå¢åŠ ï¼ŒFPä¹Ÿå¢åŠ ä»è€Œå¬å›ç‡ä¸Šå‡ï¼Œç²¾ç¡®åº¦ä¸‹é™ã€‚æé«˜IoUé˜ˆå€¼ä¼šå¯¼è‡´TPå‡å°‘ï¼ˆå®šä½è¦æ±‚æ›´ä¸¥ï¼‰ä»è€Œç²¾ç¡®åº¦å’Œå¬å›ç‡å‡å¯èƒ½ä¸‹é™ã€‚

ä¸‹é¢æ˜¯å‡ ç§ç»¼åˆæ€§çš„è¯„åˆ¤æ–¹æ³•ï¼š

F1 scoreï¼šæ˜¯Pä¸Rçš„è°ƒå’Œå¹³å‡ï¼ŒF1 = 2PR / (P + R)ã€‚ç›¸åº”çš„ä¹Ÿæœ‰F2ã€F0.5ï¼Œè¿™å–å†³äºåº”ç”¨åœºæ™¯ä¸­ä½ è®¤ä¸ºå¬å›ç‡å’Œç²¾ç¡®åº¦å“ªä¸ªæ›´é‡è¦ã€‚

P-Ræ›²çº¿ï¼šè¿™ä¸ªç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿ï¼Œæ˜¯ä»¥å¬å›ç‡ä¸ºæ¨ªè½´ï¼Œç²¾ç¡®ç‡ä¸ºçºµè½´ï¼Œå°†ç²¾ç¡®ç‡å’Œå¬å›ç‡è¿æ¥èµ·æ¥å½¢æˆä¸€æ¡æ›²çº¿ã€‚
![PR_curve](assets/PR_curve.png)
é€šè¿‡è§‚å¯Ÿç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿ï¼Œæˆ‘ä»¬å°±å¯ä»¥æ ¹æ®å…·ä½“é—®é¢˜é€‰æ‹©åˆé€‚çš„é˜ˆå€¼ï¼Œä»è€Œåœ¨ç²¾ç¡®ç‡å’Œå¬å›ç‡ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚æ¯”å¦‚åœ¨ä¸€äº›æƒ…å†µä¸‹ï¼Œæ›´é«˜çš„ç²¾ç¡®ç‡å¯èƒ½æ›´é‡è¦ï¼Œè€Œåœ¨å¦ä¸€äº›æƒ…å†µä¸‹ï¼Œæ›´é«˜çš„å¬å›ç‡å¯èƒ½æ›´ä¸ºå…³é”®ã€‚

APï¼šå¹³å‡å‡†ç¡®ç‡ï¼Œæ˜¯å¯¹ä¸åŒå¬å›ç‡ç‚¹ä¸Šçš„å‡†ç¡®ç‡è¿›è¡Œå¹³å‡ï¼Œåœ¨PRæ›²çº¿å›¾ä¸Šè¡¨ç°ä¸ºPRæ›²çº¿ä¸‹é¢çš„é¢ç§¯ã€‚APçš„å€¼è¶Šå¤§ï¼Œåˆ™è¯´æ˜æ¨¡å‹çš„å¹³å‡å‡†ç¡®ç‡è¶Šé«˜ã€‚

mAPï¼šå¹³å‡ç²¾åº¦å‡å€¼ï¼Œè¿™ä¸ªè¯å¬èµ·æ¥æœ‰äº›æ‹—å£ï¼Œæˆ‘ä»¬æ¥ä»”ç»†æ‹ä¸€æ‹ã€‚ä¸Šé¢æˆ‘ä»¬çŸ¥é“äº†ä»€ä¹ˆæ˜¯APï¼ŒAPå°±æ˜¯PRæ›²çº¿ä¸‹é¢çš„é¢ç§¯ï¼ˆå¦‚ä¸‹å›¾ï¼‰ï¼Œæ˜¯æŒ‡ä¸åŒå¬å›ç‡ä¸‹çš„ç²¾åº¦çš„å¹³å‡å€¼ã€‚ç„¶è€Œï¼Œåœ¨æˆ‘ä»¬çš„ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œä¸€ä¸ªæ¨¡å‹æ£€æµ‹åˆ°å››ç§ç±»åˆ«ï¼Œä¸”å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œæ¯ä¸€ç±»éƒ½èƒ½ç»˜åˆ¶ä¸€ä¸ªPRæ›²çº¿ï¼Œè¿›è€Œè®¡ç®—å‡ºä¸€ä¸ªAPå€¼ã€‚é‚£ä¹ˆå¤šä¸ªç±»åˆ«çš„APå€¼çš„å¹³å‡å°±æ˜¯mAPã€‚å¯ä»¥çœ‹å‡ºï¼ŒmAPé’ˆå¯¹æ•´ä¸ªæ•°æ®é›†è€Œè¨€çš„ï¼ŒAPé’ˆå¯¹æ•°æ®é›†ä¸­æŸä¸€ä¸ªç±»åˆ«è€Œè¨€çš„ï¼Œè€Œpercisionå’Œrecallé’ˆå¯¹å•å¼ å›¾ç‰‡çš„ã€‚

mAP50ä¸mAP50-95ï¼šå°†IoUè®¾ä¸º0.5æ—¶ï¼Œè®¡ç®—æ¯ä¸€ç±»çš„æ‰€æœ‰å›¾ç‰‡çš„APï¼Œç„¶åæ‰€æœ‰ç±»åˆ«æ±‚å¹³å‡ï¼Œå³mAP50ã€‚è¡¨ç¤ºåœ¨IoUä»0.5åˆ°0.95ï¼Œæ­¥é•¿0.05ï¼Œå³IoU=0.5ã€0.55ã€0.6ã€0.65ã€0.7ã€0.75ã€0.8ã€0.85ã€0.9ã€0.95ä¸Šçš„å¹³å‡mAPã€‚
# ç¬¬äºŒæ¬¡å®éªŒ
æˆ‘ä»¬åƒè¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹åœ¨æ›´ä¸¥è‹›çš„é˜ˆå€¼ä¸‹çš„è¡¨ç°ï¼Œæˆ‘ä»¬äºæ˜¯ç”¨YOLOå®˜æ–¹ç»™å‡ºçš„æ–¹æ³•è¿›è¡Œå¯»ä¼˜ï¼š
```python
import warnings
warnings.filterwarnings('ignore')
from ultralytics import YOLO
if __name__ == '__main__':
    model = YOLO('/data/coding/runs/detect/yolov8s_eucalyptus_advanced/weights/best.pt')      # éœ€è¦ä¿®æ”¹
    model.load('yolov8n.pt') # loading pretrain weights
    model.tune(data=r'/data/coding/rec/data.yaml',
                epochs=50,
                batch=32,
                close_mosaic=10,
                device='0',
                optimizer="SGD",
                workers=8,# æ•°æ®åŠ è½½çº¿ç¨‹æ•°ï¼ˆå»ºè®®=CPUæ ¸å¿ƒæ•°ï¼‰
                pretrained=True,# å¯ç”¨é¢„è®­ç»ƒæƒé‡åŠ é€Ÿæ”¶æ•›
                project='runs/train',
                iterations=15,
                name='exp',
                plots=False,
                )
```
å¾—åˆ°å¯»ä¼˜çš„ç»“æœï¼š
![tune_fitness](assets/tune_fitness.png)

å–ç¬¬åæ¬¡çš„è¶…å‚æ•°è¿›è¡Œè®­ç»ƒçš„è®¾ç½®ï¼š
```python
import warnings
warnings.filterwarnings('ignore')
from ultralytics import YOLO
 
# åŠ è½½æ¨¡å‹
model = YOLO('yolov8m.pt')
# å¼€å§‹è®­ç»ƒä»»åŠ¡
model.train(data="/data/coding/rec/data.yaml",
            epochs=200, 
            batch=16, 
            imgsz=640,
            name='yolov8s_eucalyptus_advanced',
            lr0= 0.01066,
            lrf= 0.00988,
            momentum= 0.88938,
            weight_decay= 0.00045,
            warmup_epochs= 3.63717,
            warmup_momentum= 0.88001,
            box= 7.8841,
            cls= 0.59704,
            dfl= 1.52442,
            hsv_h= 0.01474,
            hsv_s= 0.5951,
            hsv_v= 0.40185,
            degrees= 0.0,
            translate= 0.10077,
            scale= 0.63505,
            shear= 0.0,
            perspective= 0.0,
            flipud= 0.0,
            fliplr= 0.44332,
            bgr= 0.0,
            mosaic= 0.98881,
            mixup= 0.0,
            copy_paste= 0.0
            )
```
æˆ‘ä»¬å¯ä»¥å¾—åˆ°è®­ç»ƒçš„ç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š
![results](assets/results-1.png)
å®ƒåœ¨éªŒè¯é›†ä¸Šçš„mAP50-95çš„è¡¨ç°å®é™…ä¸Šæ˜¯æ›´å¥½çš„ï¼Œä½†æ˜¯å®ƒå’Œç¬¬ä¸€æ¬¡è®­ç»ƒçš„æ¨¡å‹åœ¨å…¶ä»–æŒ‡æ ‡ä¸Šç›¸å·®ä¸å¤§ï¼Œå‡ºç°è¿™æ ·çš„ç°è±¡å®é™…ä¸Šä¹Ÿå¾ˆå¥½ç†è§£ï¼ŒmAP50-95æ˜¯å¤šä¸ªIoU é˜ˆå€¼ä¸‹å¹³å‡ç²¾åº¦çš„å‡å€¼ï¼Œåæ˜ äº†æ¨¡å‹åœ¨ä¸åŒä¸¥æ ¼ç¨‹åº¦ä¸‹çš„å®šä½èƒ½åŠ›ã€‚å³ä½¿ç²¾ç¡®ç‡å’Œå¬å›ç‡åœ¨å•ä¸€é˜ˆå€¼ä¸‹å˜åŒ–ä¸å¤§ï¼Œè‹¥æ¨¡å‹åœ¨æ›´é«˜IoUé˜ˆå€¼å¦‚ 0.75ã€0.9ï¼‰ä¸‹çš„æ€§èƒ½å¾—åˆ°æå‡ï¼Œå°±ä¼šæ˜¾è‘—æ‹‰é«˜ mAP50-95ã€‚ä¹Ÿå°±æ˜¯å¤§å®¶åœ¨æ™®é€šæŒ‡æ ‡ä¸Šæ•ˆæœå·®ä¸å¤šï¼Œè€Œåœ¨æ›´ä¸¥æ ¼çš„æŒ‡æ ‡ä¸Šåè€…çš„æå‡å¤šï¼Œå°±å‡ºç°è¿™æ ·çš„ç°è±¡ã€‚
# ç¬¬ä¸‰æ¬¡å®éªŒ
æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶åè®­ç»ƒï¼š
æ³¨æ„åŠ›æœºåˆ¶ä¸€ç›´æ˜¯å¾ˆçƒ­é—¨çš„ä¼˜åŒ–æ–¹æ³•ï¼Œæˆ‘ä»¬ä¹Ÿå°è¯•äº†è¿™ä¸ªæ–¹æ³•å°è¯•å¯¹è‡ªå·±çš„æ¨¡å‹ä¼˜åŒ–ï¼Œæˆ‘ä»¬é¦–å…ˆæ˜¯å¯¹YOLOçš„ä»£ç è¿›è¡Œäº†ä¸€äº›æ”¹åŠ¨ï¼Œultralytics/nnç›®å½•ä¸‹ï¼Œå»ºSEAttention.pyæ–‡ä»¶ï¼Œåœ¨ultralytics/nn/tasks.pyä¸­éœ€è¦åŠ å…¥SEAttentionæ–‡ä»¶ï¼Œåœ¨ultralytics/nn/task.pyä¸­å¯¹parse_modelå‡½æ•°è¿›è¡Œè°ƒæ•´ï¼ŒåŠ å…¥SEæ³¨æ„åŠ›æ¨¡å‹è§£æï¼Œé€šè¿‡SEAtt_yolov8.yamlåœ¨æˆ‘ä»¬çš„å·¥ç¨‹é‡Œé¢åŠ å…¥æ³¨æ„åŠ›æœºåˆ¶åˆ°éª¨å¹²ç½‘æœ€åéƒ¨åˆ†ã€‚

å…¶ä¸­SEAttention.pyå¦‚ä¸‹ï¼š
```python
import numpy as np
import torch
from torch import nn
from torch.nn import init

class SEAttention(nn.Module):

    def __init__(self, channel=512,reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )

    def init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                init.kaiming_normal_(m.weight, mode='fan_out')
                if m.bias is not None:
                    init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                init.constant_(m.weight, 1)
                init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                init.normal_(m.weight, std=0.001)
                if m.bias is not None:
                    init.constant_(m.bias, 0)

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)

```
ultralytics/nn/tasks.pyè¦åšå¦‚ä¸‹çš„ä¿®æ”¹ï¼š
```python
from ultralytics.nn.SEAttention import SEAttention
```
æ‰¾åˆ°è¯¥æ–‡ä»¶ä¸‹çš„parse_modelå‡½æ•°ï¼Œæ·»åŠ ï¼š
```python
elif m in {SEAttention}:
    args=[ch[f],*args]
```
åˆ›å»ºSEAtt_yolov8.yamlå¦‚ä¸‹ï¼š
```python
# Ultralytics YOLO ?, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 5  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9
  - [-1, 1, SEAttention, [16]]

# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C2f, [512]]  # 12

  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C2f, [256]]  # 15 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 13], 1, Concat, [1]]  # cat head P4
  - [-1, 3, C2f, [512]]  # 18 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 10], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C2f, [1024]]  # 21 (P5/32-large)

  - [[16, 19, 22], 1, Detect, [nc]]  # Detect(P3, P4, P5)
```
ç„¶åæˆ‘ä»¬è®¾ç½®è®­ç»ƒå‚æ•°å¦‚ä¸‹ï¼š
```python
import warnings
warnings.filterwarnings('ignore')
from ultralytics import YOLO
# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
# æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶ï¼ŒSEAtt_yolov8.yaml é»˜è®¤ä½¿ç”¨çš„æ˜¯nã€‚
# SEAtt_yolov8s.yamlï¼Œåˆ™ä½¿ç”¨çš„æ˜¯sï¼Œæ¨¡å‹ã€‚
model = YOLO("ultralytics/cfg/models/v8/SEAtt_yolov8.yaml").load('yolov8n.pt')
# Use the model
if __name__ == '__main__':
    # Use the model
    results = model.train(data='/data/coding/ultralytics/data.yaml', 
    epochs=200, 
    batch=16,
    name='attention',
    imgsz=640, 
    # è¶…å‚æ•°ç¤ºä¾‹ï¼ˆéƒ¨åˆ†ï¼‰
    lr0=3e-4,  # åˆå§‹å­¦ä¹ ç‡
    lrf=0.01,   # æœ€ç»ˆå­¦ä¹ ç‡ï¼ˆä½™å¼¦é€€ç«ï¼‰
    weight_decay=0.0005,
    warmup_epochs=5, 
    iou=0.45,
    augment=True,  # å¯ç”¨é»˜è®¤å¢å¼ºï¼ˆMosaic/MixUpç­‰ï¼‰
    hsv_h=0.015,  # è‰²è°ƒå¢å¼ºå¼ºåº¦
    hsv_s=0.7,    # é¥±å’Œåº¦å¢å¼ºå¼ºåº¦
    hsv_v=0.4,    # äº®åº¦å¢å¼ºå¼ºåº¦
    box=7.0,  # æ¡†å›å½’æŸå¤±æƒé‡
    cls=1.5,  # åˆ†ç±»æŸå¤±æƒé‡ï¼ˆå¯å¢è‡³1.5æŠ‘åˆ¶è¯¯æ£€ï¼‰
    )  # è®­ç»ƒæ¨¡å‹
```
å¯ä»¥å¾—åˆ°ç»“æœå¦‚ä¸‹ï¼š
![results](assets/results-2.png)
ç»“æœä¾ç„¶æ˜¯ä¸é”™çš„ï¼Œä½†æ˜¯mAP50-95å°±æœ‰äº›ä¸å°½å¦‚äººæ„ï¼Œä½†æ˜¯æˆ‘ä»¬åœ¨éƒ¨ç½²æ­¤æ¨¡å‹åˆ°è¾¹ç¼˜è®¾å¤‡æ—¶ï¼Œè¿™ç§æ–¹æ³•ç»™FPSå¸¦æ¥äº†å·¨å¤§çš„æå‡ã€‚åº”è¯¥æ˜¯SEæ¨¡å—ä¸»è¦ç”±å…¨å±€å¹³å‡æ± åŒ–ï¼ˆGAPï¼‰+ ä¸¤ä¸ªå…¨è¿æ¥å±‚ï¼ˆFCï¼‰ç»„æˆï¼Œè®¡ç®—é‡è¿œå°äºå·ç§¯å±‚ã€‚è€Œè¾¹ç¼˜è®¾å¤‡ï¼ˆå¦‚Jetsonã€æ ‘è“æ´¾ï¼‰çš„CPU/GPUæ›´é€‚åˆæ‰§è¡Œè½»é‡çº§FCè¿ç®—ï¼Œè€ŒSEçš„GAP+FCè®¡ç®—æ•ˆç‡è¾ƒé«˜ã€‚ä¸”SEæ¨¡å—é»˜è®¤ä½¿ç”¨å‹ç¼©æ¯”ï¼ˆreduction ratioï¼Œå¦‚16ï¼‰ï¼Œå¤§å¹…å‡å°‘FCå±‚çš„å‚æ•°é‡ã€‚ä¾‹å¦‚ï¼šè¾“å…¥é€šé“æ•°=256 â†’ ä¸­é—´å±‚=256/16=16 â†’ è¾“å‡ºé€šé“æ•°=256ï¼Œè®¡ç®—é‡è¿œä½äºæ™®é€šå·ç§¯ã€‚æ€»ä¹‹å°±æ˜¯ä¸¤å¥è¯ï¼šä¸€æ˜¯åŠ¨æ€è¿›è¡Œç‰¹å¾é€‰æ‹©è°ƒæ•´ç‰¹å¾æƒé‡ï¼ŒæŠ‘åˆ¶äº†ä¸é‡è¦ç‰¹å¾ï¼Œå‡å°‘äº†æ— æ•ˆçš„ä¼ æ’­ï¼Œä¹Ÿå°±å‡å°‘äº†å†—ä½™è®¡ç®—ã€‚äºŒæ˜¯ç”¨æ›´è½»é‡çº§çš„ç»“æ„æ›¿ä»£äº†åŸæ¥çš„å¤æ‚ç»“æ„ã€‚
# ç¬¬å››æ¬¡å®éªŒ
ä¸»å¹²ç½‘ç»œæ›¿æ¢ä¸ºFasterNetæ˜¯åœ¨è¶…ä½æ€§èƒ½è®¾å¤‡ä¸Šéƒ¨ç½²æ¨¡å‹çš„å¸¸è§„æ–¹æ³•ï¼š
å°† FasterNet çš„æ ¸å¿ƒä»£ç æ·»åŠ åˆ° ultralytics/nn/modules/bock.py ä¸­ï¼Œå¹¶ä¸”åœ¨è¯¥æ–‡ä»¶çš„æœ€ä¸Šæ–¹å¼•ç”¨â€˜BasicStageâ€™ã€â€˜PatchEmbed_FasterNetâ€™ã€â€˜PatchMerging_FasterNetâ€™æ¨¡å—ã€‚åœ¨ultralytics/nn/modules/init.pyä¸ultralytics/nn/tasks.pyä¸­æ·»åŠ ä¸Šè¿°ä¸‰ä¸ªæ¨¡å—ï¼ŒåŒæ—¶åœ¨tasks.pyçš„parse_modelè§£æå‡½æ•°ä¸­æ·»åŠ FasterNetçš„è§£ææ¨¡å—ï¼Œåœ¨self.model.moduleså‡½æ•°åæ·»åŠ æ¿€æ´»FasterNetçš„æ¨¡å—ã€‚æœ€åæ·»åŠ åˆ›å»ºyolov8-FasterNet.yamlæ–‡ä»¶ã€‚

bock.pyï¼š
```python
__all__ = (
    "DFL","HGBlock","HGStem","SPP","SPPF","C1","C2","C3","C2f",
    "C2fAttn","ImagePoolingAttn","ContrastiveHead","BNContrastiveHead",
    "C3x","C3TR","C3Ghost","GhostBottleneck","Bottleneck","BottleneckCSP",
    "Proto","RepC3","ResNetLayer","RepNCSPELAN4","ELAN1","ADown","AConv",
    "SPPELAN","CBFuse","CBLinear","C3k2","C2fPSA","C2PSA","RepVGGDW",
    "CIB","C2fCIB","Attention","PSA","SCDown","TorchVision","BasicStage",
    "PatchEmbed_FasterNet","PatchMerging_FasterNet"
)
# --------------------------FasterNet----------------------------
from timm.models.layers import DropPath


class Partial_conv3(nn.Module):
    def __init__(self, dim, n_div, forward):
        super().__init__()
        self.dim_conv3 = dim // n_div
        self.dim_untouched = dim - self.dim_conv3
        self.partial_conv3 = nn.Conv2d(self.dim_conv3, self.dim_conv3, 3, 1, 1, bias=False)

        if forward == 'slicing':
            self.forward = self.forward_slicing
        elif forward == 'split_cat':
            self.forward = self.forward_split_cat
        else:
            raise NotImplementedError

    def forward_slicing(self, x):
        # only for inference
        x = x.clone()  # !!! Keep the original input intact for the residual connection later
        x[:, :self.dim_conv3, :, :] = self.partial_conv3(x[:, :self.dim_conv3, :, :])

        return x

    def forward_split_cat(self, x):
        # for training/inference
        x1, x2 = torch.split(x, [self.dim_conv3, self.dim_untouched], dim=1)
        x1 = self.partial_conv3(x1)
        x = torch.cat((x1, x2), 1)
        return x


class MLPBlock(nn.Module):
    def __init__(self,
                 dim,
                 n_div,
                 mlp_ratio,
                 drop_path,
                 layer_scale_init_value,
                 act_layer,
                 norm_layer,
                 pconv_fw_type
                 ):

        super().__init__()
        self.dim = dim
        self.mlp_ratio = mlp_ratio
        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()
        self.n_div = n_div

        mlp_hidden_dim = int(dim * mlp_ratio)
        mlp_layer = [
            nn.Conv2d(dim, mlp_hidden_dim, 1, bias=False),
            norm_layer(mlp_hidden_dim),
            act_layer(),
            nn.Conv2d(mlp_hidden_dim, dim, 1, bias=False)
        ]
        self.mlp = nn.Sequential(*mlp_layer)
        self.spatial_mixing = Partial_conv3(
            dim,
            n_div,
            pconv_fw_type
        )
        if layer_scale_init_value > 0:
            self.layer_scale = nn.Parameter(layer_scale_init_value * torch.ones((dim)), requires_grad=True)
            self.forward = self.forward_layer_scale
        else:
            self.forward = self.forward

    def forward(self, x):
        shortcut = x
        x = self.spatial_mixing(x)
        x = shortcut + self.drop_path(self.mlp(x))
        return x

    def forward_layer_scale(self, x):
        shortcut = x
        x = self.spatial_mixing(x)
        x = shortcut + self.drop_path(
            self.layer_scale.unsqueeze(-1).unsqueeze(-1) * self.mlp(x))
        return x


class BasicStage(nn.Module):
    def __init__(self,
                 dim,
                 depth=1,
                 n_div=4,
                 mlp_ratio=2,
                 layer_scale_init_value=0,
                 norm_layer=nn.BatchNorm2d,
                 act_layer=nn.ReLU,
                 pconv_fw_type='split_cat'
                 ):
        super().__init__()
        dpr = [x.item()
               for x in torch.linspace(0, 0.0, sum([1, 2, 8, 2]))]
        blocks_list = [
            MLPBlock(
                dim=dim,
                n_div=n_div,
                mlp_ratio=mlp_ratio,
                drop_path=dpr[i],
                layer_scale_init_value=layer_scale_init_value,
                norm_layer=norm_layer,
                act_layer=act_layer,
                pconv_fw_type=pconv_fw_type
            )
            for i in range(depth)
        ]

        self.blocks = nn.Sequential(*blocks_list)

    def forward(self, x):
        x = self.blocks(x)
        return x


class PatchEmbed_FasterNet(nn.Module):

    def __init__(self, in_chans, embed_dim, patch_size, patch_stride, norm_layer=nn.BatchNorm2d):
        super().__init__()
        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_stride, bias=False)
        if norm_layer is not None:
            self.norm = norm_layer(embed_dim)
        else:
            self.norm = nn.Identity()

    def forward(self, x):
        x = self.norm(self.proj(x))
        return x

    def fuseforward(self, x):
        x = self.proj(x)
        return x


class PatchMerging_FasterNet(nn.Module):

    def __init__(self, dim, out_dim, k, patch_stride2, norm_layer=nn.BatchNorm2d):
        super().__init__()
        self.reduction = nn.Conv2d(dim, out_dim, kernel_size=k, stride=patch_stride2, bias=False)
        if norm_layer is not None:
            self.norm = norm_layer(out_dim)
        else:
            self.norm = nn.Identity()

    def forward(self, x):
        x = self.norm(self.reduction(x))
        return x

    def fuseforward(self, x):
        x = self.reduction(x)
        return x
```
init.pyï¼š
```python
from .block import (....,BasicStage,PatchEmbed_FasterNet,PatchMerging_FasterNet)
tasks.pyï¼š
from ultralytics.nn.modules import (....BasicStage, PatchEmbed_FasterNet, PatchMerging_FasterNet)
base_modules = frozenset(
        {
            ....
            BasicStage,
            PatchEmbed_FasterNet,
            PatchMerging_FasterNet
        }
    )
....
#çº¦1472è¡Œ
        elif m in [BasicStage]:
            args.pop(1)
....
#åœ¨self.model.modules()æ·»åŠ 
        if type(m) is PatchEmbed_FasterNet:
            m.proj = fuse_conv_and_bn(m.proj, m.norm)
            delattr(m, 'norm')  # remove BN
            m.forward = m.fuseforward
        if type(m) is PatchMerging_FasterNet:
            m.reduction = fuse_conv_and_bn(m.reduction, m.norm)
            delattr(m, 'norm')  # remove BN
            m.forward = m.fuseforward
```
yolov8-FasterNet.yamlï¼š
```python
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 5  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, PatchEmbed_FasterNet, [40, 4, 4]]  # 0-P1/4
  - [-1, 1, BasicStage, [40, 1]]  # 1
  - [-1, 1, PatchMerging_FasterNet, [80, 2, 2]]  # 2-P2/8
  - [-1, 2, BasicStage, [80, 1]]  # 3-P3/16
  - [-1, 1, PatchMerging_FasterNet, [160, 2, 2]]  # 4
  - [-1, 8, BasicStage, [160, 1]]  # 5-P4/32
  - [-1, 1, PatchMerging_FasterNet, [320, 2, 2]] # 6
  - [-1, 2, BasicStage, [320, 1]] # 7
  - [-1, 1, SPPF, [320, 5]]  # 8


# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 5], 1, Concat, [1]]  # cat backbone P4
  - [-1, 1, C2f, [512]]  # 11

  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 3], 1, Concat, [1]]  # cat backbone P3
  - [-1, 1, C2f, [256]]  # 14 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 11], 1, Concat, [1]]  # cat head P4
  - [-1, 1, C2f, [512]]  # 17 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 8], 1, Concat, [1]]  # cat head P5
  - [-1, 1, C2f, [1024]]  # 20 (P5/32-large)

  - [[14, 17, 20], 1, Detect, [nc]]  # Detect(P3, P4, P5)
```
æˆ‘ä»¬è®¾ç½®è®­ç»ƒå‚æ•°å¦‚ä¸‹ï¼š
```python
import warnings
warnings.filterwarnings('ignore')
from ultralytics import YOLO
if __name__ == '__main__':
    model = YOLO('/data/coding/ultralytics/ultralytics/cfg/models/v8/yolov8-FasterNet.yaml')
    model.load('yolov8n.pt') # loading pretrain weights
    model.train(data='/data/coding/ultralytics/data.yaml', 
                epochs=300, 
                batch=16,
                patience=20,
                name='main',
                # è¶…å‚æ•°ç¤ºä¾‹ï¼ˆéƒ¨åˆ†ï¼‰
                lr0=3e-4,  # åˆå§‹å­¦ä¹ ç‡
                lrf=0.01,   # æœ€ç»ˆå­¦ä¹ ç‡ï¼ˆä½™å¼¦é€€ç«ï¼‰
                weight_decay=0.0005,
                warmup_epochs=5, 
                iou=0.45,
                augment=True,  # å¯ç”¨é»˜è®¤å¢å¼ºï¼ˆMosaic/MixUpç­‰ï¼‰
                hsv_h=0.015,  # è‰²è°ƒå¢å¼ºå¼ºåº¦
                hsv_s=0.7,    # é¥±å’Œåº¦å¢å¼ºå¼ºåº¦
                hsv_v=0.4,    # äº®åº¦å¢å¼ºå¼ºåº¦
                box=7.0,  # æ¡†å›å½’æŸå¤±æƒé‡
                cls=1.5,  # åˆ†ç±»æŸå¤±æƒé‡ï¼ˆå¯å¢è‡³1.5æŠ‘åˆ¶è¯¯æ£€ï¼‰
                )
```
å¾—åˆ°çš„è®­ç»ƒç»“æœå¦‚ä¸‹ï¼š
![results](assets/results-3.png)
é™¤äº†mAP50-95çš„è¡¨ç°ä¸ä½³ï¼Œæˆ‘ä»¬ä¾ç„¶æœ‰å¾ˆå¥½çš„æ€§èƒ½è¡¨ç°ï¼Œè€Œä¸”åœ¨è¶…ä½æ€§èƒ½çš„è¾¹ç¼˜è®¾å¤‡ä¸Šçš„è¡¨ç°åŠå…¶ä¼˜ç§€ã€‚
